{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torchvision\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import PIL.ImageOps    \n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SiameseLSTM(nn.Module):\n",
    "    hdim1 = 32\n",
    "#     hdim2 = 64\n",
    "    def __init__(self, embedding_dim, vocab_size):\n",
    "        super(SiameseLSTM, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocabsize, embedding_dim)\n",
    "        self.lstm1 = nn.LSTM(embedding_dim, hdim1)\n",
    "#         self.lstm2 = nn.LSTM(hdim1, hdim2)\n",
    "        self.output = nn.Linear(hdim1, 1)\n",
    "        \n",
    "        self.hidden1 = self.initHidden(hdim1)\n",
    "#         self.hidden2 = self.initHidden(hdim2)\n",
    "        \n",
    "    def initHidden(self, dim):\n",
    "        return (autograd.Variable(torch.zeros(1, 1, dim)),\n",
    "        autograd.Variable(torch.zeros(1, 1, dim)))\n",
    "        \n",
    "    def forward_once(self, lyric):\n",
    "        embeds = self.word_embeddings(lyric)\n",
    "        lstm_out, self.hidden1 = self.lstm1(\n",
    "            embeds.view(len(sentence), 1, -1), self.hidden1)\n",
    "        return self.output(lstm_out.view(len(sentence), -1))\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        return F.softmax(-torch.abs(output1-output2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#helper functions\n",
    "def openFile(path):\n",
    "    f = open(path, \"r\")\n",
    "    return f.read() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LyricDataset(Dataset):\n",
    "    def __init__(self, pathToData, should_invert=True, numClasses):\n",
    "        self.pathToData = pathToData\n",
    "        self.should_invert = should_invert\n",
    "        self.numClasses = numClasses\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        labels = os.listdir(self.pathToData)\n",
    "        sameClass = random.randint(0,1)\n",
    "        song1 = None\n",
    "        song2 = None\n",
    "        if sameClass: \n",
    "            label = random.randint(0, numClasses-1)\n",
    "            classPath = self.pathToData + \"/\" + labels[label]\n",
    "            songs = os.listdir(classPath)\n",
    "            index1 = random.randint(0,len(songs))\n",
    "            s1Path = classPath + \"/\" + songs[index1]\n",
    "            index2 = index1 \n",
    "            while index2 == index1:\n",
    "                index2 = random.randint(0,len(songs))\n",
    "            s2Path = classPath + \"/\" + songs[index2]\n",
    "\n",
    "        else:\n",
    "            label1 = random.randint(0, numClasses-1)\n",
    "            label2 = label1\n",
    "            while label2 == label1:\n",
    "                label2 = random.randint(0, numClasses-1)\n",
    "            classPath1 = self.pathToData + \"/\" + labels[label1]\n",
    "            songs1 = os.listdir(classPath1)\n",
    "            index1 = random.randint(0,len(songs1))\n",
    "            s1Path = classPath + \"/\" + songs[index1]\n",
    "            \n",
    "            classPath2 = self.pathToData + \"/\" + labels[label2]\n",
    "            songs2 = os.listdir(classPath2)\n",
    "            index2 = random.randint(0,len(songs2))\n",
    "            s2Path = classPath + \"/\" + songs[index2]\n",
    "            \n",
    "        s1 = openFile(s1Path)\n",
    "        song1 = s1.split(\" \")\n",
    "        s2 = openFile(s2Path)\n",
    "        song2 = s2.split(\" \")\n",
    "        \n",
    "        return song1, song2, sameClass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH = \"Users/alexchan/Documents/college/susa/LyricNet/train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EDIM = 32\n",
    "\n",
    "model = SiameseLSTM(EDIM, length)\n",
    "loss = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
